{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPHxiGL+lgaXH1ftEPGEIEV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RubenMcCarty/Machine-Learning-con-Python-001/blob/master/EVALUACI%C3%93N_T1_Laboratorio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EVALUACIÓN T1 INTELIGENCIA ARTIFICIAL Y SISTEMAS EXPERTOS\n",
        "# Profesor: [M.Sc. Ruben Quispe](https://www.linkedin.com/in/ruben-quispe-l)\n",
        "# Nombre completo:"
      ],
      "metadata": {
        "id": "LD5l0ij8MQYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mas alla de Hola Mundo un ejemplo de Vision Artificial\n",
        "En la primera semana, vio cómo crear una red neuronal que descubrió el problema que estaba tratando de resolver. Esto dio un ejemplo explícito de comportamiento aprendido. Por supuesto, en ese caso, fue un poco exagerado porque hubiera sido más fácil escribir la función Y = 2x + 1 directamente, en lugar de molestarse en usar Machine Learning para aprender la relación entre X e Y para un conjunto fijo de valores, y extendiendo eso para todos los valores.\n",
        "\n",
        "Pero, ¿qué pasa con un escenario en el que escribir reglas como esa es mucho más difícil, por ejemplo, un problema de visión por computadora? Echemos un vistazo a un escenario en el que podemos reconocer diferentes prendas de vestir, entrenadas a partir de un conjunto de datos que contiene 10 tipos diferentes."
      ],
      "metadata": {
        "id": "_BYxczmiQLD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Iniciando con codigo\n",
        "Comencemos con nuestra importación de TensorFlow"
      ],
      "metadata": {
        "id": "z73N_4fSQtbA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oxKCr9TKMJQy"
      },
      "outputs": [],
      "source": [
        "# ejecute la celda de comandos\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenaremos una red neuronal para reconocer prendas de ropa de un conjunto de datos común llamado Fashion MNIST. Puede obtener más información sobre este conjunto de datos [aqui](https://github.com/zalandoresearch/fashion-mnist).\n",
        "\n",
        "Contiene 70.000 prendas de vestir en 10 categorías diferentes. Cada prenda de vestir tiene una imagen en escala de grises de 28x28. Puedes ver algunos ejemplos aquí:![](https://raw.githubusercontent.com/zalandoresearch/fashion-mnist/master/doc/img/fashion-mnist-sprite.png)"
      ],
      "metadata": {
        "id": "xwWWgMqqRCGz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los datos de Fashion MNIST están disponibles directamente en la API de conjuntos de datos de tf.keras. Lo cargas así:"
      ],
      "metadata": {
        "id": "bCJ5CTltRcuv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecute el comando \n",
        "# mnist = tf.keras.datasets.fashion_mnist\n",
        "# tu código"
      ],
      "metadata": {
        "id": "eDJ7dxSVQ5wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Llamar a load_data en este objeto le dará dos conjuntos de dos listas, estos serán los valores de entrenamiento y prueba para los gráficos que contienen las prendas y sus etiquetas."
      ],
      "metadata": {
        "id": "s4hs4PRURzEy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecute el comando \n",
        "#(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# tu código"
      ],
      "metadata": {
        "id": "3xktCwBvR953"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cómo se ven estos valores? Imprima una imagen de entrenamiento y una etiqueta de entrenamiento para ver ... Experimente con diferentes índices en la matriz. Por ejemplo, también eche un vistazo al índice 42 ... es un arranque diferente al del índice 0 Código Texto"
      ],
      "metadata": {
        "id": "MB6KgAwHSPPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ejecute la celda con los index 0,5,10,20,100 y describa que prenda es?\n",
        "\n",
        "#import matplotlib.pyplot as plt\n",
        "#plt.imshow(training_images[0])\n",
        "#print(training_labels[0])\n",
        "#print(training_images[0])\n",
        "#tu código"
      ],
      "metadata": {
        "id": "RhhTCBPMSHwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notarás que todos los valores en el número están entre 0 y 255. Si estamos entrenando una red neuronal, por varias razones es más fácil si tratamos todos los valores entre 0 y 1, un proceso llamado \"normalización\". .y afortunadamente en Python es fácil normalizar una lista como esta sin hacer bucles. Lo haces así:"
      ],
      "metadata": {
        "id": "eXOytgBNToEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código para normalizar\n",
        "#training_images  = training_images / 255.0\n",
        "#test_images = test_images / 255.0\n",
        "# escribe tu código"
      ],
      "metadata": {
        "id": "FYNlH-f5UQCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Puede que ahora te preguntes por qué hay 2 conjuntos ... entrenamiento (TRAINING) y prueba (TEST). ¿Recuerdas que hablamos de esto en la introducción? La idea es tener 1 conjunto de datos para el entrenamiento, y luego otro conjunto de datos ... que el modelo aún no ha visto ... para ver qué tan bueno sería clasificando valores. Después de todo, cuando haya terminado, querrá probarlo con datos que no había visto anteriormente."
      ],
      "metadata": {
        "id": "1iVHoUbQUeOb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diseñemos ahora el modelo. Hay bastantes conceptos nuevos aquí, pero no se preocupe, los dominará."
      ],
      "metadata": {
        "id": "sFRfBz1YU7ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecute el código\n",
        "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu), \n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])"
      ],
      "metadata": {
        "id": "wIlfWyFmU3So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Sequential**: que define una SECUENCIA de capas en la red neuronal.\n",
        "\n",
        "**Flaten**: ¿Recuerda antes donde nuestras imágenes eran un cuadrado, cuando las imprimió? Flatten solo toma ese cuadrado y lo convierte en un conjunto de 1 dimensión.\n",
        "\n",
        "**Dense**: agrega una capa de neuronas\n",
        "\n",
        "Cada capa de neuronas necesita una función de activación que les diga qué hacer. Hay muchas opciones, pero úsalas por ahora.\n",
        "\n",
        "**Relu** significa efectivamente \"Si X> 0 devuelve X, de lo contrario devuelve 0\", por lo que lo que hace solo pasa valores 0 o mayores a la siguiente capa de la red.\n",
        "\n",
        "**Softmax** toma un conjunto de valores y efectivamente elige el más grande, así que, por ejemplo, si la salida de la última capa se ve como [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05], guarda el mayor valor, y lo convierte en [0,0,0,0,1,0,0,0,0] - ¡El objetivo es ahorrar mucha codificación!"
      ],
      "metadata": {
        "id": "bfNHf16eVURC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo siguiente que debe hacer, ahora que el modelo está definido, es construirlo. Para hacer esto, compilalo con un optimizador y una función de pérdida como antes, y luego lo entrena llamando a model.fit pidiéndole que ajuste sus datos de entrenamiento a sus etiquetas de entrenamiento, es decir, que averigüe la relación entre los datos de entrenamiento y sus etiquetas reales, por lo que en el futuro, si tiene datos que se parecen a los datos de entrenamiento, puede hacer una predicción de cómo se verían esos datos."
      ],
      "metadata": {
        "id": "OArYaX-UVsQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecute tu código\n",
        "#model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "#model.fit(training_images, training_labels, epochs=5)"
      ],
      "metadata": {
        "id": "S9XzJ9w1VZHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Una vez que haya terminado el entrenamiento, debería ver un valor de precisión al final de la época final. Puede parecer algo así como 0.9098. Esto le indica que su red neuronal tiene una precisión del 91% en la clasificación de los datos de entrenamiento. Es decir, descubrió una coincidencia de patrón entre la imagen y las etiquetas que funcionó el 91% del tiempo. No es genial, pero no está mal considerando que solo se entrenó durante 5 épocas y se hizo con bastante rapidez.\n",
        "\n",
        "Pero, ¿cómo funcionaría con datos invisibles? Por eso tenemos las imágenes de prueba. Podemos llamar model.evaluate y pasar los dos conjuntos, e informará la pérdida de cada uno. Hagamos un intento:"
      ],
      "metadata": {
        "id": "NObykTRWWEQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ejecute el código\n",
        "# model.evaluate(test_images, test_labels)"
      ],
      "metadata": {
        "id": "K-gd6207WFBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para mí, eso arrojó una precisión de aproximadamente .8838, lo que significa que fue aproximadamente un 88% de precisión. Como se esperaba, probablemente no funcionaría tan bien con datos no vistos como lo hizo con los datos sobre los que se entrenó. A medida que avance en este curso, verá formas de mejorarlo.\n",
        "\n",
        "Para explorar más, pruebe los siguientes ejercicios:"
      ],
      "metadata": {
        "id": "nKQtQWxwWWgL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "muERIl0TWXDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploration Exercises"
      ],
      "metadata": {
        "id": "SXE191VMWuDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1:\n",
        "Para este primer ejercicio, ejecute el siguiente código: Crea un conjunto de clasificaciones para cada una de las imágenes de prueba y luego imprime la primera entrada en las clasificaciones. La salida, después de ejecutarla, es una lista de números. ¿Por qué crees que es así y qué representan esos números?"
      ],
      "metadata": {
        "id": "WaSPw7IyXBYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código\n",
        "# classifications = model.predict(test_images)\n",
        "\n",
        "#print(classifications[0])"
      ],
      "metadata": {
        "id": "FUmUp2hMWvwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sugerencia: intente ejecutar print (test_labels [0]) y obtendrá un 9. ¿Eso le ayuda a comprender por qué esta lista se ve como es?"
      ],
      "metadata": {
        "id": "oq_OOAcy1UlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "JAx_hnUV1WO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Qué representa esta lista?\n",
        "1. Son 10 valores aleatorios sin sentido\n",
        "2. Son las primeras 10 clasificaciones que hizo la computadora\n",
        "3. Es la probabilidad de que este elemento sea de cada una de las 10 clases"
      ],
      "metadata": {
        "id": "GVpyayIN1mI1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Respuesta 1:\n",
        "La respuesta correcta es (3)\n",
        "\n",
        "La salida del modelo es una lista de 10 números. Estos números son una probabilidad de que el valor que se está clasificando sea el valor correspondiente, es decir, el primer valor de la lista es la probabilidad de que la escritura a mano sea un '0', el siguiente sea un '1', etc. Observe que todos son MUY BAJAS probabilidades.\n",
        "\n",
        "Para el 7, la probabilidad era .999+, es decir, la red neuronal nos dice que es casi seguro que es un 7."
      ],
      "metadata": {
        "id": "zClrJTTp2q4b"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TiI0a4-M1mv0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ¿Cómo sabe que esta lista le dice que el artículo es un botín?\n",
        "No hay suficiente información para responder esa pregunta.\n",
        "El décimo elemento de la lista es el más grande y el botín tiene la etiqueta 9\n",
        "El botín es la etiqueta 9, y hay 0-> 9 elementos en la lista"
      ],
      "metadata": {
        "id": "EKlK8Zid3Gev"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Responder\n",
        "La respuesta correcta es (2). Tanto la lista como las etiquetas se basan en 0, por lo que el botín con la etiqueta 9 significa que es el décimo de las 10 clases. La lista en la que el décimo elemento es el valor más alto significa que la red neuronal ha predicho que el elemento que está clasificando es muy probablemente un botín"
      ],
      "metadata": {
        "id": "G6s5dWMx3dZk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2:\n",
        "Veamos ahora las capas de su modelo. Experimente con diferentes valores para la capa densa con 512 neuronas. ¿Qué resultados diferentes obtienes por pérdida, tiempo de entrenamiento, etc.? ¿Por qué crees que ese es el caso?"
      ],
      "metadata": {
        "id": "aTRqFXDl3tng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(1024, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "uCASR33c3v19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3:\n",
        "¿Qué pasaría si eliminas la capa Flatten ()? ¿Por qué crees que ese es el caso?\n",
        "\n",
        "Obtiene un error sobre la forma de los datos. Puede parecer vago en este momento, pero refuerza la regla general de que la primera capa de su red debe tener la misma forma que sus datos. En este momento, nuestros datos son imágenes de 28x28, y 28 capas de 28 neuronas serían inviables, por lo que tiene más sentido 'aplanar' esas 28,28 en un 784x1. En lugar de escribir todo el código para manejar eso nosotros mismos, agregamos la capa Flatten () al principio, y cuando las matrices se carguen en el modelo más adelante, automáticamente se aplanarán para nosotros."
      ],
      "metadata": {
        "id": "GWoaOIfu2lPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# This version has the 'flatten' removed. Replace the above with this one to see the error.\n",
        "#model = tf.keras.models.Sequential([tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "dVith5NE2l4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4:\n",
        "\n",
        "Considere las capas finales (de salida). ¿Por qué hay 10 de ellos? ¿Qué pasaría si tuvieras una cantidad diferente a 10? Por ejemplo, intente entrenar la red con 5\n",
        "\n",
        "Obtiene un error tan pronto como encuentra un valor inesperado. Otra regla general: la cantidad de neuronas en la última capa debe coincidir con la cantidad de clases para las que está clasificando. En este caso, son los dígitos 0-9, por lo que hay 10 de ellos, por lo que debe tener 10 neuronas en su capa final."
      ],
      "metadata": {
        "id": "JilesckqAYON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "# Replace the above model definiton with this one to see the network with 5 output layers\n",
        "# And you'll see errors as a result!\n",
        "# model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "#                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "#                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "WwCnzpAo-jHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 5:\n",
        "\n",
        "Considere los efectos de capas adicionales en la red. ¿Qué pasará si agregas otra capa entre la que tiene 512 y la capa final con 10?\n",
        "\n",
        "Respuesta: No hay un impacto significativo, porque se trata de datos relativamente simples. Para datos mucho más complejos (incluidas las imágenes en color que se clasificarán como flores que verá en la próxima lección), a menudo se necesitan capas adicionales. "
      ],
      "metadata": {
        "id": "vCW3sgjNBBgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "TFkXRBjlAgZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 6:\n",
        "\n",
        "Considere el impacto del entrenamiento durante más o menos épocas. ¿Por qué crees que sería así?\n",
        "\n",
        "Pruebe 15 épocas: probablemente obtendrá un modelo con una pérdida mucho mejor que el que tiene 5\n",
        "Pruebe 30 épocas; es posible que vea que el valor de pérdida deja de disminuir y, a veces, aumenta. Este es un efecto secundario de algo llamado \"sobreajuste\" del que puede aprender [en algún lugar] y es algo que debe tener en cuenta al entrenar redes neuronales. No tiene sentido perder el tiempo entrenando si no está mejorando su pérdida, ¿verdad? :)"
      ],
      "metadata": {
        "id": "H_uZo5FKBF9y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "id": "NLc7girxBFq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 7:\n",
        "\n",
        "Antes de entrenar, normalizó los datos, pasando de valores que eran 0-255 a valores que eran 0-1. ¿Cuál sería el impacto de eliminar eso? Aquí está el código completo para probarlo. ¿Por qué crees que obtienes resultados diferentes?"
      ],
      "metadata": {
        "id": "2iSHOWnMBRQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "# To experiment with removing normalization, comment out the following 2 lines\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "id": "1c0bOhISBRxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejercicio 8:\n",
        "\n",
        "Antes, cuando entrenó para épocas adicionales, tuvo un problema en el que su pérdida podría cambiar. Es posible que te haya llevado un poco de tiempo esperar a que el entrenamiento lo haga, y quizás hayas pensado '¿no sería bueno si pudiera detener el entrenamiento cuando alcance el valor deseado?' - es decir, el 95% de precisión podría ser suficiente para ti, y si lo alcanzas después de 3 épocas, ¿por qué quedarte esperando a que termine muchas más épocas? Como cualquier otro programa ... ¡tienes devoluciones de llamada! Veámoslos en acción ..."
      ],
      "metadata": {
        "id": "UrP2YuSsBb3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.9):\n",
        "      print(\"\\nReached 90% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "C3NxtfXqBdEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Regresión Polinómica para predecir Emisión de CO2\n",
        "____"
      ],
      "metadata": {
        "id": "uGQnqTjNOqFH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sobre este Notebook\n",
        "En este notebook, aprenderas a usar scikit learn para regresión polinómica. Descargue o cargue el dataset de consumo de combustible y la emisión de CO2 de los automóviles, proporcionados por el profesor. Luego dividimos nuestros datos en conjuntos de train y test, creamos un modelo usando el conjunto de train, evaluamos nuestro modelo usando el test set y finalmente usamos el modelo para predecir el valor desconocido."
      ],
      "metadata": {
        "id": "aMt5BTtFOzWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nuestro dataset comprende estos datos\n",
        "Hemos descargado un conjunto de datos de consumo de combustible, FuelConsumption.csv, que contiene clasificaciones de consumo de combustible específicas del modelo y emisiones estimadas de dióxido de carbono para los vehículos ligeros nuevos para la venta minorista en Canadá. [Dataset](https://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)\n",
        "1. MODELYEAR e.g. 2014\n",
        "2. MAKE e.g. Acura\n",
        "3. MODEL e.g. ILX\n",
        "4. VEHICLE CLASS e.g. SUV\n",
        "5. ENGINE SIZE e.g. 4.7\n",
        "6. CYLINDERS e.g 6\n",
        "7. TRANSMISSION e.g. A6\n",
        "8. FUEL CONSUMPTION in CITY(L/100 km) e.g. 9.9\n",
        "9. FUEL CONSUMPTION in HWY (L/100 km) e.g. 8.9\n",
        "10. FUEL CONSUMPTION COMB (L/100 km) e.g. 9.2\n",
        "11. CO2 EMISSIONS (g/km) e.g. 182 --> low --> 0"
      ],
      "metadata": {
        "id": "IoSUIhzNxWmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Importando las librerias necesarias "
      ],
      "metadata": {
        "id": "ePrbR90YxbC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "4Zl8u4gJOr-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load-cargar o Leer la data "
      ],
      "metadata": {
        "id": "Nw70ORTUxg6N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "2_9YLqTtxftF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lee las 9 primeras filas del dataset\n"
      ],
      "metadata": {
        "id": "1ZtWZOotyff-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "VFpiEHPYxw4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "lee las 10 ultimas columnas del dataset "
      ],
      "metadata": {
        "id": "nZMrTtCqyqbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "iRbHaxu4ypit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zPT7vdvPy6FY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprima el tamaño de dataset"
      ],
      "metadata": {
        "id": "EiXn5otNy_pX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "bC0_ON6pzC1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprima datos estadísticos e indica la media del dataset"
      ],
      "metadata": {
        "id": "KGC7rop3zP3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "wca5dWeJzE6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprima el valor de la intersección de la fila 10 con la columna CO2 EMISSIONS (Es decir el valor emitido de CO2 del coche de la fila 10)"
      ],
      "metadata": {
        "id": "P9HdBcufzgYP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "_P5FKb62zffn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprima el valor de la intersección de la fila 1000 y la columna enginesize"
      ],
      "metadata": {
        "id": "6sdcQjF50U3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "vPGnxC5i0HKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# seleccionamos algunas caracteristicas \n",
        "# cdf = df[['ENGINESIZE', 'CYLINDERS', 'FUELCONSUMPTION_COMB', 'CO2EMISSIONS']]\n"
      ],
      "metadata": {
        "id": "phjF-kj80tUQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "imprima las 10 primeras y ultimas filas de tu dataset"
      ],
      "metadata": {
        "id": "h2noZGOn1De_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "0t2PeAk_0kPO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Graficar los valores de emisión de CO2 respecto a Tamaño de motor"
      ],
      "metadata": {
        "id": "IC7342dB1dYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tu código"
      ],
      "metadata": {
        "id": "wdQGpXem1Nol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Crear un conjunto de datos de train y test\n",
        "La división de conjunto de Train/Test, implica dividir el dataset en train set y test set, que son mutuamente excluyentes. Despues se debe entrenar con el train set y probar con el test set."
      ],
      "metadata": {
        "id": "Zsy21PfX1mVp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tu código"
      ],
      "metadata": {
        "id": "-D5rtUYa1lo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Regresión Polinomial\n",
        "A veces, la tendencia de los datos no es realmente lineal y parece curvilínea. En este caso podemos utilizar métodos de regresión polinomial. De hecho, existen muchas regresiones diferentes que pueden usarse para ajustarse a cualquier aspecto del conjunto de datos, como cuadrático, cúbico, etc.y puede continuar hasta grados infinitos.\n",
        "\n",
        "En esencia, podemos llamar a todos estos regresión polinomial, donde la relación entre la variable independiente x y la variable dependiente y se modela como un polinomio de enésimo grado en x. Digamos que desea tener una regresión polinomial (hagamos un polinomio de 2 grados):\n",
        "\n",
        "$𝑦 = 𝑏 + \\theta_1𝑥 + \\theta_2𝑥^2 $\n",
        "Ahora, la pregunta es: ¿cómo podemos ajustar nuestros datos en esta ecuación mientras solo tenemos valores x, como el tamaño del motor? Bueno, podemos crear algunas características adicionales: 1, $𝑥$ y $𝑥^2$.\n",
        "\n",
        "La función **Ploynomial Features()** en la biblioteca Scikit-learn, impulsa un nuevo conjunto de características del conjunto de características original. Es decir, se generará una matriz que consta de todas las combinaciones polinomiales de las características con grado menor o igual al grado especificado. Por ejemplo, digamos que el conjunto de características original tiene solo una característica, ENGINESIZE. Ahora, si seleccionamos el grado del polinomio para que sea 2, entonces genera 3 características, grado = 0, grado = 1 y grado = 2:"
      ],
      "metadata": {
        "id": "t6IEjIUy2I41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn import linear_model\n",
        "train_x =np.asanyarray(train[['ENGINESIZE']])\n",
        "train_y = np.asanyarray(train[['CO2EMISSIONS']])\n",
        "\n",
        "test_x = np.asanyarray(test[['ENGINESIZE']])\n",
        "test_y = np.asanyarray(test[['CO2EMISSIONS']])\n",
        "\n",
        "poly = PolynomialFeatures(degree=2)\n",
        "train_x_poly = poly.fit_transform(train_x)\n",
        "train_x_poly "
      ],
      "metadata": {
        "id": "vnh-R3Ds2IUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**fit_transform** toma nuestros valores de x y genera una lista de nuestros datos elevados desde la potencia de 0 a la potencia de 2 (ya que establecemos el grado de nuestro polinomio en 2).\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    v_1\\\\\n",
        "    v_2\\\\\n",
        "    \\vdots\\\\\n",
        "    v_n\n",
        "\\end{bmatrix}\n",
        "$\n",
        "$\\longrightarrow$\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    [ 1 & v_1 & v_1^2]\\\\\n",
        "    [ 1 & v_2 & v_2^2]\\\\\n",
        "    \\vdots & \\vdots & \\vdots\\\\\n",
        "    [ 1 & v_n & v_n^2]\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "in our example\n",
        "\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    2.\\\\\n",
        "    2.4\\\\\n",
        "    1.5\\\\\n",
        "    \\vdots\n",
        "\\end{bmatrix}\n",
        "$\n",
        "$\\longrightarrow$\n",
        "$\n",
        "\\begin{bmatrix}\n",
        "    [ 1 & 2. & 4.]\\\\\n",
        "    [ 1 & 2.4 & 5.76]\\\\\n",
        "    [ 1 & 1.5 & 2.25]\\\\\n",
        "    \\vdots & \\vdots & \\vdots\\\\\n",
        "\\end{bmatrix}\n",
        "$\n",
        "\n",
        "Parecen conjuntos de características para análisis de regresión lineal múltiple, ¿verdad? Si. Lo hace. De hecho, la regresión polinomial es un caso especial de regresión lineal, con la idea principal de cómo seleccionar sus características. Solo considere reemplazar $𝑥$ con $𝑥1$, $𝑥_1^2$ con $𝑥_2$, y así sucesivamente. Entonces la ecuación de grado 2 se convertiría en:\n",
        "\n",
        "$𝑦 = 𝑏 + \\theta_1 𝑥_1 +\\theta_2 𝑥2$\n",
        "\n",
        "Ahora, podemos tratarlo como un problema de \"regresión lineal\". Por lo tanto, esta regresión polinomial se considera un caso especial de regresión lineal múltiple tradicional. Entonces, puede usar el mismo mecanismo que la regresión lineal para resolver tales problemas.\n",
        "\n",
        "así que podemos usar la función **LinearRegression()** para resolverlo:"
      ],
      "metadata": {
        "id": "R5vZpqN1Kx63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf = linear_model.LinearRegression()\n",
        "train_y_ = clf.fit(train_x_poly, train_y)\n",
        "# The coefficients\n",
        "print ('Coefficients: ', clf.coef_)\n",
        "print ('Intercept: ',clf.intercept_)"
      ],
      "metadata": {
        "id": "0Um4RQMoLUg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se mencionó anteriormente, Coeficiente e Intercepción, son los parámetros de la línea curva ajustada. Dado que es una regresión lineal múltiple típica, con 3 parámetros, y sabiendo que los parámetros son la intersección y los coeficientes del hiperplano, sklearn los ha estimado a partir de nuestro nuevo conjunto de conjuntos de características. Vamos a trazarlo:"
      ],
      "metadata": {
        "id": "lVHIwVddLiB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(train.ENGINESIZE, train.CO2EMISSIONS,  color='blue')\n",
        "XX = np.arange(0.0, 10.0, 0.1)\n",
        "yy = clf.intercept_[0]+ clf.coef_[0][1]*XX+ clf.coef_[0][2]*np.power(XX, 2)\n",
        "plt.plot(XX, yy, '-r' )\n",
        "plt.xlabel(\"Engine size\")\n",
        "plt.ylabel(\"Emission\")"
      ],
      "metadata": {
        "id": "6FjdrrWZLjVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5.Evaluación"
      ],
      "metadata": {
        "id": "LKPpwuUvQxEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score\n",
        "\n",
        "test_x_poly = poly.fit_transform(test_x)\n",
        "test_y_ = clf.predict(test_x_poly)\n",
        "\n",
        "print(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\n",
        "print(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\n",
        "print(\"R2-score: %.2f\" % r2_score(test_y_ , test_y) )"
      ],
      "metadata": {
        "id": "ZB3kNPBVQxo5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Práctica\n",
        "Intente utilizar una regresión polinomial con el conjunto de datos, pero esta vez con grado tres (cúbico). ¿Da como resultado una mejor precisión?"
      ],
      "metadata": {
        "id": "9B9yrMmxQ-Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Escribe tu codigo aqui"
      ],
      "metadata": {
        "id": "HN14fKFXQ91A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}